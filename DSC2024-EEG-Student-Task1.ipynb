{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b33e13df",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "For this task, you will use the data recorded while participants completed a range of motor/imagery tasks. \n",
    "The full details of the experimental task are available via this link : \n",
    "[link to physionet data repository](https://physionet.org/content/eegmmidb/1.0.0/S002/#files-panel)\n",
    "\n",
    "The reference related to the study is:\n",
    "\n",
    "*Schalk, G., McFarland, D.J., Hinterberger, T., Birbaumer, N., Wolpaw, J.R. BCI2000: A General-Purpose Brain-Computer Interface (BCI) System. IEEE Transactions on Biomedical Engineering 51(6):1034-1043, 2004.*\n",
    "\n",
    "### Dataset description \n",
    "\n",
    "64-channel EEG was recorded while participants performed different motor/imagery tasks. \n",
    " Each subject performed 14 experimental runs: two one-minute baseline runs (one with eyes open, one with eyes closed), and three two-minute runs of each of the four following tasks:\n",
    "\n",
    "- **Task 1** A target appears on either the left or the right side of the screen. The subject opens and closes the corresponding fist until the target disappears. Then the subject relaxes.\n",
    "\n",
    "- **Task 2** A target appears on either the left or the right side of the screen. The subject imagines opening and closing the corresponding fist until the target disappears. Then the subject relaxes.\n",
    "\n",
    "- **Task 3** A target appears on either the top or the bottom of the screen. The subject opens and closes either both fists (if the target is on top) or both feet (if the target is on the bottom) until the target disappears. Then the subject relaxes.\n",
    "\n",
    "- **Task 4** A target appears on either the top or the bottom of the screen. The subject imagines opening and closing either both fists (if the target is on top) or both feet (if the target is on the bottom) until the target disappears. Then the subject relaxes.\n",
    "\n",
    "For this task you have data from the two baseline runs and from Tasks 1 and 2 for a single participant. \n",
    "The data is in .EDF+ format (European data format).\n",
    "The EEGs were recorded from 64 electrodes as per the international 10-10 system (excluding electrodes Nz, F9, F10, FT9, FT10, A1, A2, TP9, TP10, P9, and P10)\n",
    "\n",
    "The datasets are in the data folder, which can be accessed via this amubox link: \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b6143d",
   "metadata": {},
   "source": [
    "## Task 1 instructions\n",
    "\n",
    "Using the script **DSC2024-EEG-Script1_students** as a guide carry out the following:\n",
    "\n",
    "- Load in one the datasets (**eyes open**) of one of the baseline runs and visualize the raw data. \n",
    "- Extract the following dataset information:\n",
    "    - the sampling frequency (Hz)\n",
    "    - the names and the type of the channels\n",
    "    - the time vector \n",
    "- Determine and display the temporal resolution of the dataset. \n",
    "- Do you need to remove the DC component? Do this if needed.\n",
    "- What reference will you apply to the data? Plot the referenced data. \n",
    "- Can you spot any artifacts in the data? Can you identify the artifact?\n",
    "- Present a **temporal** and **spatial** visualization of the artifact. For the temporal visualization you can plot one or several individual electrodes. \n",
    "\n",
    "- Load in the dataset corresponding to the second baseline run (**eyes closed**) and carry out the same visualisation and processing steps as for the first baseline run. Then compare the two datasets.\n",
    "\n",
    "Do you notice any differences between the two? \n",
    "If so, present figures that highlight these differences. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c024b037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put your code in cells here. Maybe a cell per answer...\n",
    "# Don't forget to import the required packages.\n",
    "\n",
    "\n",
    "# Help for loading in the *.edf file:\n",
    "rawIn = mne.io.read_raw_edf(fullpath, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd6514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
